%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Humberto Stein Shiromoto at 2023-01-11 22:40:54 +1100 


%% Saved with string encoding Unicode (UTF-8) 



@misc{Ost20,
	author = {D. Ostwald},
	date-added = {2023-01-11 22:39:41 +1100},
	date-modified = {2023-01-11 22:40:51 +1100},
	howpublished = {Online},
	month = {Jan},
	title = {The general linear model},
	year = {2020}}

@book{ORe17,
	author = {G. O'Regan},
	date-added = {2023-01-10 20:54:13 +1100},
	date-modified = {2023-01-10 20:55:01 +1100},
	publisher = {Springer},
	title = {Concise Guide to Software Engineering},
	year = {2017}}

@book{IguSeg17,
	author = {L. Igual and S. Segu\'{i}},
	date-added = {2023-01-10 20:52:45 +1100},
	date-modified = {2023-01-10 20:53:22 +1100},
	publisher = {Springer},
	title = {Introduction to Data Science},
	year = {2017}}

@book{Lee17,
	author = {K. D. Lee},
	date-added = {2023-01-10 20:52:14 +1100},
	date-modified = {2023-01-10 20:52:38 +1100},
	publisher = {Springer},
	title = {Foundations of Programming Languages},
	year = {2017}}

@book{For18,
	author = {D. Forsyth},
	date-added = {2023-01-10 20:51:36 +1100},
	date-modified = {2023-01-10 20:52:01 +1100},
	publisher = {Springer},
	title = {Probability and Statistics for Computer Science},
	year = {2018}}

@book{Bra18,
	author = {M. Bramer},
	date-added = {2023-01-10 20:51:10 +1100},
	date-modified = {2023-01-10 20:51:30 +1100},
	publisher = {Springer},
	title = {Principles of Data Mining},
	year = {2018}}

@book{Agg16,
	author = {C. C. Aggarwal},
	date-added = {2023-01-10 20:50:18 +1100},
	date-modified = {2023-01-10 20:50:51 +1100},
	publisher = {Springer},
	title = {Recommender Systems},
	year = {2016}}

@book{Agg18,
	author = {C. C. Aggarwal},
	date-added = {2023-01-10 20:45:45 +1100},
	date-modified = {2023-01-10 20:50:08 +1100},
	publisher = {Springer},
	title = {Neural Networks and Deep Learning},
	year = {2018}}

@book{CF09,
	author = {G. W. Corder and D. I. Foreman},
	date-added = {2022-12-30 07:37:05 +1100},
	date-modified = {2022-12-30 07:37:24 +1100},
	title = {Nonparametric Statistics for Non-Statisticians: A Step-by-Step Approach},
	year = {2009}}

@book{Mur22,
	author = {K. P. Murphy},
	date-added = {2022-08-28 22:09:51 +1000},
	date-modified = {2022-08-28 22:11:28 +1000},
	publisher = {MIT Press},
	title = {Probabilistic Machine Learning: An Introduction},
	year = {2022}}

@book{HilGriLim18,
	author = {R. C. Hill and W. E. Griffiths and G. C. Lim},
	date-added = {2022-08-28 21:54:54 +1000},
	date-modified = {2022-08-28 21:58:27 +1000},
	publisher = {John Wiley \& Sons},
	title = {Principles of Econometrics},
	year = {2018}}

@misc{PetPed1211,
	author = {K. B. Petersen and M. S. Pedersen},
	date-added = {2022-08-28 21:41:19 +1000},
	date-modified = {2022-08-28 21:42:24 +1000},
	howpublished = {online},
	keywords = {Matrix identity, matrix relations, inverse, matrix derivative},
	month = {November},
	title = {The Matrix Cookbook},
	year = {2012}}

@book{DegSch12,
	author = {H. M. DeGroot and M. J. Schervish},
	date-added = {2022-08-28 21:35:33 +1000},
	date-modified = {2022-08-28 21:37:26 +1000},
	editor = {4th},
	publisher = {Pearson},
	title = {Probability and Statistics},
	year = {2012}}

@book{Yan19,
	abstract = {Introduction to Algorithms for Data Mining and Machine Learning introduces the essential ideas behind all key algorithms and techniques for data mining and machine learning, along with optimization techniques. Its strong formal mathematical approach, well selected examples, and practical software recommendations help readers develop confidence in their data modeling skills so they can process and interpret data for classification, clustering, curve-fitting and predictions. Masterfully balancing theory and practice, it is especially useful for those who need relevant, well explained, but not rigorous (proofs based) background theory and clear guidelines for working with big data.
                   
                   Key Features
                   
                   Presents an informal, theorem-free approach with concise, compact coverage of all fundamental topics
                   Includes worked examples that help users increase confidence in their understanding of key algorithms, thus encouraging self-study
                   Provides algorithms and techniques that can be implemented in any programming language, with each chapter including notes about relevant software packages
                   
                   # Table of Contents
                   
                   1 - Introduction to optimization
                   2 - Mathematical foundations
                   3 - Optimization algorithms
                   4 - Data fitting and regression
                   5 - Logistic regression, PCA, LDA, and ICA
                   6 - Data mining techniques
                   7 - Support vector machine and regression
                   8 - Neural networks and deep learning
                   },
	author = {X.-S. Yang},
	date-added = {2022-01-12 14:16:44 +1100},
	date-modified = {2022-01-12 14:17:46 +1100},
	doi = {10.1016/c2018-0-02034-4},
	publisher = {Academic Press},
	title = {Introduction to Algorithms for Data Mining and Machine Learning},
	url = {https://doi.org/10.1016/c2018-0-02034-4},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1016/c2018-0-02034-4}}

@book{ShuSto17,
	abstract = {The fourth edition of this popular graduate textbook, like its predecessors, presents a balanced and comprehensive treatment of both time and frequency domain methods with accompanying theory. Numerous examples using nontrivial data illustrate solutions to problems such as discovering natural and anthropogenic climate change, evaluating pain perception experiments using functional magnetic resonance imaging, and monitoring a nuclear test ban treaty.
                   The book is designed as a textbook for graduate level students in the physical, biological, and social sciences and as a graduate level text in statistics. Some parts may also serve as an undergraduate introductory course. Theory and methodology are separated to allow presentations on different levels. In addition to coverage of classical methods of time series regression, ARIMA models, spectral analysis and state-space models, the text includes modern developments including categorical time series analysis, multivariate spectral methods, long memory series, nonlinear models, resampling techniques, GARCH models, ARMAX models, stochastic volatility, wavelets, and Markov chain Monte Carlo integration methods.
                   
                   This edition includes R code for each numerical example in addition to Appendix R, which provides a reference for the data sets and R scripts used in the text in addition to a tutorial on basic R commands and R time series. An additional file is available on the book's website for download, making all the data sets and scripts easy to load into R.
                   
                   Student-tested and improved
                   Accessible and complete treatment of modern time series analysis
                   Promotes understanding of theoretical concepts by bringing them into a more practical context
                   Comprehensive appendices covering the necessities of understanding the mathematics of time series analysis
                   Instructor's Manual available for adopters
                   
                   New to this edition:
                   
                   Introductions to each chapter replaced with one-page abstracts
                   All graphics and plots redone and made uniform in style
                   Bayesian section completely rewritten, covering linear Gaussian state space models only
                   R code for each example provided directly in the text for ease of data analysis replication
                   Expanded appendices with tutorials containing basic R and R time series commands
                   Data sets and additional R scripts available for download on Springer.com
                   Internal online links to every reference (equations, examples, chapters, etc.)
                   
                   # Table of Contents
                   
                   
                   Characteristics of Time Series
                   Time Series Regression and Exploratory Data Analysis
                   ARIMA Models
                   Spectral Analysis and Filtering
                   Additional Time Domain Topics
                   State Space Models
                   Statistical Methods in the Frequency Domain},
	author = {R. H. Shumway and D. S. Stoffer},
	date-added = {2021-12-25 22:27:46 +1100},
	date-modified = {2021-12-25 22:30:08 +1100},
	doi = {10.1007/978-3-319-52452-8},
	edition = {4th},
	keywords = {ARIMA models; dynamic linear models; R; spectral analysis; categorical time series analysis; multivariate spectral methods; long memory series; nonlinear models; resampling techniques; GARCH models; state-space analysis; stochastic volatility; wavelets; integration method; Markov chain; Monte Carlo integration method},
	publisher = {Springer},
	series = {Springer Texts in Statistics},
	title = {Time Series Analysis and Its Applications},
	url = {https://doi.org/10.1007/978-3-319-52452-8},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-52452-8}}

@book{Ski08,
	abstract = {....The most comprehensive guide to designing practical and efficient algorithms!....
                   
                   The Algorithm Design Manual, Second Edition
                   
                   "...the book is an algorithm-implementation treasure trove, and putting all of these implementations in one place was no small feat. The list of implementations [and] extensive bibliography make the book an invaluable resource for everyone interested in the subject." --ACM Computing Reviews
                   
                   "It has all the right ingredients: rich contents, friendly, personal language, subtle humor, the right references, and a plethora of pointers to resources." -- P. Takis Metaxas, Wellesley College
                   
                   "This is the most approachable book on algorithms I have." -- Megan Squire, Elon University, USA
                   
                   This newly expanded and updated second edition of the best-selling classic continues to take the "mystery" out of designing algorithms, and analyzing their efficacy and efficiency. Expanding on the first edition, the book now serves as the primary textbook of choice for algorithm design courses while maintaining its status as the premier practical reference guide to algorithms for programmers, researchers, and students.
                   
                   The reader-friendly Algorithm Design Manual provides straightforward access to combinatorial algorithms technology, stressing design over analysis. The first part, Techniques, provides accessible instruction on methods for designing and analyzing computer algorithms. The second part, Resources, is intended for browsing and reference, and comprises the catalog of algorithmic resources, implementations and an extensive bibliography.
                   
                   NEW to the second edition:
                   
                   * Doubles the tutorial material and exercises over the first edition
                   
                   * Provides full online support for lecturers, and a completely updated and improved website component with lecture slides, audio and video
                   
                   * Contains a unique catalog identifying the 75 algorithmic problems that arise most often in practice, leading the reader down the right path to solve them
                   
                   * Includes several NEW "war stories" relating experiences from real-world applications
                   
                   * Provides up-to-date links leading to the very best algorithm implementations available in C, C++, and Java
                   
                   ADDITIONAL Learning Tools:
                   
                   * Exercises include "job interview problems" from major software companies
                   
                   * Highlighted take-home lesson boxes emphasize essential concepts
                   
                   * Provides comprehensive references to both survey articles and the primary literature
                   
                   * Exercises point to relevant programming contest challenge problems
                   
                   * Many algorithms presented with actual code (written in C) as well as pseudo-code
                   
                   * A full set of lecture slides and additional material available at www.algorist.com
                   
                   Written by a well-known algorithms researcher who received the IEEE Computer Science and Engineering Teaching Award, this new edition of The Algorithm Design Manual is an essential learning tool for students needing a solid grounding in algorithms, as well as a special text/reference for professionals who need an authoritative and insightful guide. Professor Skiena is also author of the popular Springer text, Programming Challenges: The Programming Contest Training Manual.
                   
                   # Table of Contents
                   
                   Introduction to Algorithm Design
                   Algorithm Analysis
                   Data Structures
                   Sorting and Searching
                   Graph Traversal
                   Weighted Graph Algorithms
                   Combinatorial Search and Heuristic Methods
                   Dynamic Programming
                   Intractable Problems and Approximation Algorithms
                   How to Design Algorithms
                   
                   The Hitchhiker's Guide to Algorithms
                   A Catalog of Algorithmic Problems
                   Data Structures
                   Numerical Problems
                   Combinatorial Problems
                   Graph Problems: Polynomial-Time
                   Graph Problems: Hard Problems
                   Computational Geometry
                   Set and String Problems
                   Algorithmic Resources},
	author = {S. S. Skiena},
	date-added = {2021-12-23 15:26:10 +1100},
	date-modified = {2021-12-23 15:29:59 +1100},
	doi = {10.1007/978-1-84800-070-4},
	edition = {2nd},
	keywords = {algorithms; analysis; C++; Java; algorithm; computational geometry; computer science; data structure; design programming; structured analysis; algorithm analysis; problem complexity},
	publisher = {Springer},
	title = {The Algorithm Design Manual},
	url = {https://doi.org/10.1007/978-1-84800-070-4},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-84800-070-4}}

@book{Ski17,
	abstract = {This engaging and clearly written textbook/reference provides a must-have introduction to the rapidly emerging interdisciplinary field of data science. It focuses on the principles fundamental to becoming a good data scientist and the key skills needed to build systems for collecting, analyzing, and interpreting data.
                   
                   The Data Science Design Manual is a source of practical insights that highlights what really matters in analyzing data, and provides an intuitive understanding of how these core concepts can be used. The book does not emphasize any particular programming language or suite of data-analysis tools, focusing instead on high-level discussion of important design principles.
                   This easy-to-read text ideally serves the needs of undergraduate and early graduate students embarking on an ``Introduction to Data Science'' course. It reveals how this discipline sits at the intersection of statistics, computer science, and machine learning, with a distinct heft and character of its own. Practitioners in these and related fields will find this book perfect for self-study as well.
                   
                   Additional learning tools:
                   
                   Contains ``War Stories,'' offering perspectives on how data science applies in the real world
                   Includes ``Homework Problems,'' providing a wide range of exercises and projects for self-study
                   Provides a complete set of lecture slides and online video lectures at www.data-manual.com
                   Provides ``Take-Home Lessons,'' emphasizing the big-picture concepts to learn from each chapter
                   Recommends exciting ``Kaggle Challenges'' from the online platform Kaggle
                   Highlights ``False Starts,'' revealing the subtle reasons why certain approaches fail
                   Offers examples taken from the data science television show ``The Quant Shop'' (www.quant-shop.com)
                   
                   # Table of Contents
                   
                   
                   What is Data Science?
                   Mathematical Preliminaries
                   Data Munging
                   Scores and Rankings
                   Statistical Analysis
                   Visualizing Data
                   Mathematical Models
                   Linear Algebra
                   Linear and Logistic Regression
                   Distance and Network Methods
                   Machine Learning
                   Big Data: Achieving Scale
                   Coda
                   },
	author = {S. S. Skiena},
	date-added = {2021-12-23 15:23:23 +1100},
	date-modified = {2021-12-23 15:25:32 +1100},
	doi = {10.1007/978-3-319-55444-0},
	keywords = {data science; data analytics; pattern recognition; analytical statistics; data visualisation;},
	publisher = {Springer},
	series = {Texts in Computer Science},
	title = {The Data Science Design Manual},
	url = {https://doi.org/10.1007/978-3-319-55444-0},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-55444-0}}

@book{HasTibFri09,
	abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.
                   
                   This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates.
                   
                   Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.
                   
                   # Table of Contents
                   
                   
                   Overview of Supervised Learning
                   Linear Methods for Regression
                   Linear Methods for Classification
                   Basis Expansions and Regularization
                   Kernel Smoothing Methods
                   Model Assessment and Selection
                   Model Inference and Averaging
                   Additive Models, Trees, and Related Methods
                   Boosting and Additive Trees
                   Neural Networks
                   Support Vector Machines and Flexible Discriminants
                   Prototype Methods and Nearest-Neighbors
                   Unsupervised Learning
                   Random Forests
                   Ensemble Learning
                   Undirected Graphical Models
                   High-Dimensional Problems: p N},
	author = {T. Hastie and R. Tibshirani and J. Friedman},
	date-added = {2021-12-23 15:19:37 +1100},
	date-modified = {2021-12-23 15:21:17 +1100},
	doi = {10.1007/978-0-387-84858-7},
	keywords = {averaging; boosting; projection pursuit; random forest; support vector machine; classification; clustering; data mining; supervised learning; unsupervised learning;},
	publisher = {Springer},
	title = {The Elements of Statistical Learning},
	url = {https://doi.org/10.1007/978-0-387-84858-7},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1007/978-0-387-84858-7}}

@book{JamWitHas21,
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, deep learning, survival analysis, multiple testing, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.
                   
                   Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.
                   
                   This Second Edition features new chapters on deep learning, survival analysis, and multiple testing, as well as expanded treatments of na{\"\i}ve Bayes, generalized linear models, Bayesian additive regression trees, and matrix completion. R code has been updated throughout to ensure compatibility.
                   
                   # Table of Contents
                   
                   
                   Statistical Learning
                   Linear Regression
                   Classification
                   Resampling Methods
                   Linear Model Selection and Regularization
                   Moving Beyond Linearity
                   Tree-Based Methods
                   Support Vector Machines
                   Deep Learning
                   Survival Analysis and Censored Data
                   Unsupervised Learning
                   Multiple Testing},
	author = {G. James and D. Witten and T. Hastie and R. Tibshirani},
	date-added = {2021-12-23 15:16:53 +1100},
	date-modified = {2021-12-23 15:18:48 +1100},
	doi = {10.1007/978-1-0716-1418-1},
	keywords = {R; data mining; inference; statistical learning; supervised learning; unsupervised learning;},
	publisher = {Springer},
	title = {An Introduction to Statistical Learning},
	url = {https://doi.org/10.1007/978-1-0716-1418-1},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-0716-1418-1}}

@book{Kub17,
	abstract = {This textbook presents fundamental machine learning concepts in an easy to understand manner by providing practical advice, using straightforward examples, and offering engaging discussions of relevant applications. The main topics include Bayesian classifiers, nearest-neighbor classifiers, linear and polynomial classifiers, decision trees, neural networks, and support vector machines. Later chapters show how to combine these simple tools by way of ``boosting,'' how to exploit them in more complicated domains, and how to deal with diverse advanced practical issues. One chapter is dedicated to the popular genetic algorithms.
                   
                   This revised edition contains three entirely new chapters on critical topics regarding the pragmatic application of machine learning in industry. The chapters examine multi-label domains, unsupervised learning and its use in deep learning, and logical approaches to induction as well as Inductive Logic Programming. Numerous chapters have been expanded, and the presentation of the material has been enhanced. The book contains many new exercises, numerous solved examples, thought-provoking experiments, and computer assignments for independent work.
                   
                   # Table of Contents
                   
                   A Simple Machine-Learning Task
                   Probabilities: Bayesian Classifiers
                   Similarities: Nearest-Neighbor Classifiers
                   Inter-Class Boundaries: Linear and Polynomial Classifiers
                   Artificial Neural Networks
                   Decision Trees
                   Computational Learning Theory
                   A Few Instructive Applications
                   Induction of Voting Assemblies
                   Some Practical Aspects to Know About
                   Performance Evaluation
                   Statistical Significance
                   Induction in Multi-Label Domains
                   Unsupervised Learning
                   Classifiers in the Form of Rulesets
                   The Genetic Algorithm
                   Reinforcement Learning},
	author = {M. Kubat},
	date-added = {2021-12-23 15:12:07 +1100},
	date-modified = {2021-12-23 15:15:01 +1100},
	doi = {10.1007/978-3-319-63913-0},
	keywords = {bayesian classifiers; boosting; computational learning theory; decision trees; genetic algorithms; linear and polynomial classifiers; nearest neighbor classifier; neural networks; performance evaluation; reinforcement learning; statistical learning; time-varying classes; imbalanced representation; artificial intelligence; deep learning; unsupervised learning;},
	publisher = {Springer},
	title = {An Introduction to Machine Learning},
	url = {https://doi.org/10.1007/978-3-319-63913-0},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-63913-0}}
