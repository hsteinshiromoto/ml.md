An ensemble learning strategy that sequentially trains a series of [[weak models]], each one attempting to correctly predict the observations that the previous model got wrong. 

As opposed to [[bagging]], boosting trains on all the data and combines [[weak models]] using the [[learning rate]] $\alpha$.